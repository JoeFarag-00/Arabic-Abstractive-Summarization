{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\Cuda\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Anaconda\\envs\\Cuda\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Anaconda\\envs\\Cuda\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Anaconda\\envs\\Cuda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>وتحت عنوان من الكارثة إلى التحدى يبدأ الكاتب ع...</td>\n",
       "      <td>يبدأ الكاتب عرض الكتاب الرابع تحت عنوان من الك...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ولم يعترف دبلوماسيو هاتين الدولتين بالعريضة ال...</td>\n",
       "      <td>دبلوماسيو الدولتين لم يعترفوا بالعريضة التي قا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>قامت ولاية حلب بعد اعلان الجنرال الفرنسي هنري ...</td>\n",
       "      <td>أعلن غورو الانتداب الفرنسي على سوريا لكي يعاقب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>دولة مصر العربيه هي ليست اي دوله وليست اي شعب ...</td>\n",
       "      <td>مصر هي أم البلاد، وقائدة العرب؛ فهي أرض بلاد ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>السوريون يصرون على استقلال بلادهم : و مثلما رف...</td>\n",
       "      <td>الشعب السوري يصر على استقلال بلدهم من السيطرة ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id                                          paragraph  \\\n",
       "0           0  وتحت عنوان من الكارثة إلى التحدى يبدأ الكاتب ع...   \n",
       "1           1  ولم يعترف دبلوماسيو هاتين الدولتين بالعريضة ال...   \n",
       "2           2  قامت ولاية حلب بعد اعلان الجنرال الفرنسي هنري ...   \n",
       "3           3  دولة مصر العربيه هي ليست اي دوله وليست اي شعب ...   \n",
       "4           4  السوريون يصرون على استقلال بلادهم : و مثلما رف...   \n",
       "\n",
       "                                             summary  \n",
       "0  يبدأ الكاتب عرض الكتاب الرابع تحت عنوان من الك...  \n",
       "1  دبلوماسيو الدولتين لم يعترفوا بالعريضة التي قا...  \n",
       "2  أعلن غورو الانتداب الفرنسي على سوريا لكي يعاقب...  \n",
       "3  مصر هي أم البلاد، وقائدة العرب؛ فهي أرض بلاد ا...  \n",
       "4  الشعب السوري يصر على استقلال بلدهم من السيطرة ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_json('../Datasets/AIC Val/ds.jsonl', lines=True)\n",
    "DF.head()\n",
    "# DF = pd.read_csv('../Datasets\\WikiHow\\wikiHow.csv', nrows=2000)\n",
    "# DF.columns = ['summary', 'paragraph']\n",
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paragraphs = DF['paragraph'].tolist()\n",
    "Summaries = DF['summary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Paragraphs, Test_Paragraphs, Train_Summaries, Test_Summaries = train_test_split(Paragraphs, Summaries, test_size=0.2, random_state=42)\n",
    "Train_Paragraphs, Validation_Paragraphs, Train_Summaries, Validation_Summaries = train_test_split(Train_Paragraphs, Train_Summaries, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
      "The class this function is called from is 'MBartTokenizer'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "Model_Name = \"facebook/mbart-large-50\"\n",
    "Tokenizer = MBartTokenizer.from_pretrained(Model_Name)\n",
    "Model = MBartForConditionalGeneration.from_pretrained(Model_Name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paragraph_Max_Length = 512\n",
    "Train_Paragraph_Encodings = Tokenizer(Train_Paragraphs, truncation=True, max_length=Paragraph_Max_Length, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "Validation_Paragraph_Encodings = Tokenizer(Validation_Paragraphs, truncation=True, max_length=Paragraph_Max_Length, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "Test_Paragraph_Encodings = Tokenizer(Test_Paragraphs, truncation=True, max_length=Paragraph_Max_Length, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "Summary_Max_Length = 64\n",
    "Train_Summary_Encodings = Tokenizer(Train_Summaries, truncation=True, max_length=Summary_Max_Length, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "Validation_Summary_Encodings = Tokenizer(Validation_Summaries, truncation=True, max_length=Summary_Max_Length, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "Test_Summary_Encodings = Tokenizer(Test_Summaries, truncation=True, max_length=Summary_Max_Length, padding=\"max_length\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask):\n",
    "        self.input_ids = input_ids.to(device)\n",
    "        self.attention_mask = attention_mask.to(device)\n",
    "        self.decoder_input_ids = decoder_input_ids.to(device)\n",
    "        self.decoder_attention_mask = decoder_attention_mask.to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"decoder_input_ids\": self.decoder_input_ids[idx],\n",
    "            \"decoder_attention_mask\": self.decoder_attention_mask[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dataset = CustomDataset(\n",
    "    Train_Paragraph_Encodings['input_ids'],\n",
    "    Train_Paragraph_Encodings['attention_mask'],\n",
    "    Train_Summary_Encodings['input_ids'],\n",
    "    Train_Summary_Encodings['attention_mask']\n",
    ")\n",
    "\n",
    "Validation_Dataset = CustomDataset(\n",
    "    Validation_Paragraph_Encodings['input_ids'],\n",
    "    Validation_Paragraph_Encodings['attention_mask'],\n",
    "    Validation_Summary_Encodings['input_ids'],\n",
    "    Validation_Summary_Encodings['attention_mask']\n",
    ")\n",
    "\n",
    "Test_Dataset = CustomDataset(\n",
    "    Test_Paragraph_Encodings['input_ids'],\n",
    "    Test_Paragraph_Encodings['attention_mask'],\n",
    "    Test_Summary_Encodings['input_ids'],\n",
    "    Test_Summary_Encodings['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dataloader = DataLoader(Train_Dataset, batch_size=1)\n",
    "Validation_Dataloader = DataLoader(Validation_Dataset, batch_size=1)\n",
    "Test_Dataloader = DataLoader(Test_Dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 98/98 [07:51<00:00,  4.81s/batch, Loss_Average=2.9, Rouge1_Average=0.129, Rouge2_Average=0.0204, RougeL_Average=0.129, loss=1.2]    \n",
      "Epoch 2/5: 100%|██████████| 98/98 [07:54<00:00,  4.84s/batch, Loss_Average=1.29, Rouge1_Average=0.194, Rouge2_Average=0.0408, RougeL_Average=0.194, loss=1.14]  \n",
      "Epoch 3/5: 100%|██████████| 98/98 [07:56<00:00,  4.86s/batch, Loss_Average=0.554, Rouge1_Average=0.112, Rouge2_Average=0.0102, RougeL_Average=0.112, loss=0.0218]  \n",
      "Epoch 4/5: 100%|██████████| 98/98 [07:43<00:00,  4.73s/batch, Loss_Average=0.0118, Rouge1_Average=0.194, Rouge2_Average=0.0408, RougeL_Average=0.194, loss=0.00827] \n",
      "Epoch 5/5: 100%|██████████| 98/98 [07:50<00:00,  4.80s/batch, Loss_Average=0.0138, Rouge1_Average=0.194, Rouge2_Average=0.0408, RougeL_Average=0.194, loss=0.00312] \n"
     ]
    }
   ],
   "source": [
    "Optimizer = torch.optim.AdamW(Model.parameters(), lr=1e-5)\n",
    "Criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "Epochs_Number = 5\n",
    "\n",
    "Scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
    "\n",
    "for Epoch in range(Epochs_Number):\n",
    "    Model.train()\n",
    "    Total_Loss = 0\n",
    "\n",
    "    Total_Rouge1 = 0.0\n",
    "    Total_Rouge2 = 0.0\n",
    "    Total_RougeL = 0.0\n",
    "    Total_Batches = 0\n",
    "    with tqdm(Train_Dataloader, desc=f\"Epoch {Epoch + 1}/{Epochs_Number}\",  unit=\"batch\") as t:\n",
    "        for Batch in t:\n",
    "            Input_IDs = Batch[\"input_ids\"].to(device)\n",
    "            Attention_Mask = Batch[\"attention_mask\"].to(device)\n",
    "            Decoder_Input_IDs = Batch[\"decoder_input_ids\"].to(device)\n",
    "            Decoder_Attention_Mask = Batch[\"decoder_attention_mask\"].to(device)\n",
    "\n",
    "            # print(\"Input IDs Shape:\", Input_IDs.shape)\n",
    "            # print(\"Attention Mask Shape:\", Attention_Mask.shape)\n",
    "            # print(\"Decoder Input IDs Shape:\", Decoder_Input_IDs.shape)\n",
    "            # print(\"Decoder Attention Mask Shape:\", Decoder_Attention_Mask.shape)\n",
    "\n",
    "            Outputs = Model(\n",
    "                input_ids=Input_IDs,\n",
    "                attention_mask=Attention_Mask,\n",
    "                decoder_input_ids=Decoder_Input_IDs,\n",
    "                decoder_attention_mask=Decoder_Attention_Mask,\n",
    "                labels=Decoder_Input_IDs\n",
    "            )\n",
    "\n",
    "            # IDs = Tokenizer.batch_decode(Input_IDs, skip_special_tokens=True)\n",
    "            # decoded_output = Tokenizer.batch_decode(Outputs.logits.argmax(dim=-1), skip_special_tokens=True)\n",
    "            # print(IDs)\n",
    "            # print(decoded_output)\n",
    "\n",
    "            Loss = Outputs.loss\n",
    "            Total_Loss += Loss.item()\n",
    "\n",
    "            Optimizer.zero_grad()\n",
    "            Loss.backward()\n",
    "            Optimizer.step()\n",
    "\n",
    "            Reference_sentences = Tokenizer.batch_decode(Decoder_Input_IDs, skip_special_tokens=True)\n",
    "            Generated_sentences = Tokenizer.batch_decode(Outputs.logits.argmax(dim=-1), skip_special_tokens=True)\n",
    "\n",
    "            Scores = Scorer.score(''.join(Reference_sentences), ''.join(Generated_sentences))\n",
    "            Total_Rouge1 += Scores['rouge1'].fmeasure\n",
    "            Total_Rouge2 += Scores['rouge2'].fmeasure\n",
    "            Total_RougeL += Scores['rougeL'].fmeasure\n",
    "            Total_Batches += 1\n",
    "\n",
    "            t.set_postfix(\n",
    "                Loss_Average=Total_Loss / len(Train_Dataloader),\n",
    "                loss=Loss.item(),\n",
    "                Rouge1_Average=Total_Rouge1 / Total_Batches,\n",
    "                Rouge2_Average=Total_Rouge2 / Total_Batches,\n",
    "                RougeL_Average=Total_RougeL / Total_Batches\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Save_Path = 'mBart.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Model.state_dict(), Model_Save_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.eval()\n",
    "\n",
    "Predicted_Summaries = []\n",
    "\n",
    "with tqdm(Train_Dataloader, unit=\"batch\") as t:\n",
    "    for Batch in t:\n",
    "        Input_IDs = Batch[\"input_ids\"]\n",
    "        Attention_Mask = Batch[\"attention_mask\"]\n",
    "        Outputs = Model.generate(\n",
    "            input_ids=Input_IDs,\n",
    "            attention_mask=Attention_Mask,\n",
    "            max_length=Summary_Max_Length,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "         \n",
    "        print(Outputs)\n",
    "        IDs = Tokenizer.batch_decode(Input_IDs, skip_special_tokens=True)\n",
    "        print(IDs)\n",
    "        Batch_Summaries = Tokenizer.batch_decode(Outputs, skip_special_tokens=True)\n",
    "        print(Batch_Summaries)\n",
    "        Predicted_Summaries.extend(Batch_Summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'التاريخ يقول ان غزو \" ا آشوريا \" لمصر حصل في القرن السابع قبل الميلاد واحتلت على اثره مصر لمدة تقارب المائة سنة تخللها مقاومة وحروب وقلاقل وثورات من المصريين لمقاومة الاحتلال الآشوري وفي النهاية استطاع المصريون طرد الآشوريين الغزاة لكن ما لبثوا ان غزاهم الفرس في منتصف القرن السادس قبل الميلاد وسقطت مصر في أيدي الفرس ورزحت تحت الاحتلال الفارسي قرابة 180 سنة بعد ان احتلها الآشوريون لمدة تقارب قرنا من الزمان ثم جاء اليونانيون بقيادة الإسكندر الأكبر المقدوني واحتل مصر وانهى الحقبة الفارسية في مصر واستمر حكم البطالمة لمصر قرابة ثلاثة قرون وما كادت مصر تخرج من نفوذ الحكم اليوناني حتى وقعت تحت الحكم الروماني واسمر حتى سقط على يد عمرو بن العاص فدخلت مصر تحت حكم العرب الى اليوم وان كان تخلله فترات حكم مصر خلالها المماليك والاخشيديون وأخيرا العثمانيون الأتراك وخضعت فترة قصيرة للانتداب البريطاني حتى نالت استقلالها وتأسست جمهورية مصر الحديثة واذا استثنينا فترة الانتداب البريطاني فان كل الحكومات من بعد الفتح الاسلامي لمصر حكومات إسلامية .. ومنذ الفتح الاسلامي لمصر توافد العرب زرافات الى مصر من جزيرة العرب ونلاحظ ان تاريخ مصر السياسي والحضاري المدون بدأ منذ تول الاسرة الفرعونية الاولى قبل 3500 سنة قبل الميلاد وهي بهذا تعد اقدم حضارة في العالم تم تدوينها .. وكان الحكام والمحكومين وقتها افارقة محليين يمكن ان نقول عنهم اصحاب السلالة الجينية e وهي السلالة الجينية لافارقة جنوب الصحراء ( أمازيغ ونوبيين وحبش ) .. وانتهى حكم مصر وخرج من أيدي الحكام المحليين بدخول الإسكندر الأكبر المقدوني لمصر .. وفي ظني ان السلالة الجينية j2 دخلت مصر مع قدوم الآشوريين والفرس الى مصر ودخلت السلالة الجينية j1 مع دخول الآشوريين ايضا لان بعض الساميين اختلطوا مع الاشوريين في الامبراطورية الآشورية وكانوا ضمن المكون الاجتماعي في الإمبراطوريات الاشورية والبابلية والسومرية في العراق والشام لكن ازداد ضخ السلالة الجينية j1 في مصر بعد الفتح الاسلامي لمصر ومن هنا نستنتج ان السلالة الجينية للمصريين الأصليين هي e والسلالتين الجينيتين j1,j2 للوافدين الأجانب الى مصر وكذلك يجب ان لا ننسى السلالة الجينية الهندواوروبية r التي دخلت مصر مع دخول البطالمة اليونان مصر والسلالات الجينية الأوروبية الاخرى دخلت مصر بدخول الرومان لمصر . وبناء على ما تقدم فانه من غير المستغرب ان تظهر المومياوات التي يصل عمرها الى ما يقارب الألف سنة قبل الميلاد على سلالات جينية (j1,j2,r) بجوار السلالة الجينية المحلية e'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.load_state_dict(torch.load(Model_Save_Path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBartForConditionalGeneration(\n",
      "  (model): MBartModel(\n",
      "    (shared): Embedding(250054, 1024, padding_idx=1)\n",
      "    (encoder): MBartEncoder(\n",
      "      (embed_tokens): Embedding(250054, 1024, padding_idx=1)\n",
      "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): MBartDecoder(\n",
      "      (embed_tokens): Embedding(250054, 1024, padding_idx=1)\n",
      "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=250054, bias=False)\n",
      ")\n",
      "<class 'transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration'>\n"
     ]
    }
   ],
   "source": [
    "print(Model)\n",
    "print(type(Model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'تاريخ أقول غزو \" آشوريا \" مصر حصل قرن سابع ميلاد احتال ثرا مصر مد تقارب المائة تخلل مقاوم حروب وقلاقل ثور مصري مقاوم احتلال الآشوري نهاية استطاع مصري طرد الآشوريين غزاة لبث غز فرس منتصف قرن سادس ميلاد سقط مصر يد فرس رزح احتلال فارس قراب ١٨٠ احتل الآشوريون مد تقارب قرن زم جاء يوناني قياد الإسكندر أكبر مقدوني حتل مصر وانهى حقب فارس مصر استمر حكم البطالمة مصر قراب قرون ما كاد مصر تخرج نفوذ حكم يونان وقع حكم رومان سمر سقط يد عمر العاص دخل مصر حكم عرب تخلل فتر حكم مصر خلال مماليك والاخشيديون أخير عثماني الأتراك خضع فترة قصير انتداب بريطاني نال استقلال تأسس جمهور مصر حديث واذا استثنى فترة انتداب بريطاني حكومة فتح الاسلامي مصر حكومة إسلام منذ فتح الاسلامي مصر توافد عرب زرافة مصر جزيرة عرب لاحظ تاريخ مصر سياسة حضار مدون بدأ تولي الاسرة فرعون ٣٥٠٠ ميلاد تعدي قدم حضار عالم تدوين حكام محكوم وقت افارقة محلي نقول عن اصحاب سلال جين e سلال جين لافارقة جنوب صحراء ( أمازيغ نوبي حبش ) انتهى حكم مصر خرج يد حكام محلي دخول الإسكندر أكبر مقدوني مصر ظن سلال جين j٢ دخل مصر قدوم الآشوريين فرس مصر دخل سلال جين j١ دخول الآشوريين لان الساميين اختلط الاشوريين الامبراطورية الآشورية كانو مكون اجتماع إمبراطوري الاشورية بابلي سومر عراق والشام ازداد ضخ سلال جين j١ مصر فتح الاسلامي مصر استنتج سلال جين مصري أصلي e سلال جين j١ j٢ وافد أجانب مصر ذلك جبى نسى سلال جين الهندواوروبية r دخل مصر دخول البطالمة يونان مصر سلال جين أوروبي الاخرى دخل مصر دخول روم مصر بناء تقدم مستغرب ظهر المومياوات صلى عمر قارب ألف ميلاد سلال جين ( j١ j٢ r ) جوار سلال جين محل e'\n",
    "\n",
    "input_ids = Tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "summary_ids = Model.generate(input_ids, max_length=100, num_beams=4, decoder_start_token_id=Model.config.pad_token_id)\n",
    "\n",
    "summary = Tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436\n",
      "تاريخ أقول غزو \" آشوريا \" مصر حصل قرن سابع ميلاد احتال ثرا مصر مد تقارب المائة تخلل مقاوم حروب وقلاقل ثور مصري مقاوم احتلال الآشوري نهاية استطاع مصري طرد الآشوريين غزاة لبث غز فرس منتصف قرن سادس ميلاد سقط مصر يد فرس رزح احتلال فارس قراب ١٨٠ احتل الآشوريون مد تقارب قرن زم جاء يوناني قياد الإسكندر أكبر مقدوني حتل مصر وانهى حقب فارس مصر استمر حكم البطالمة مصر قراب قرون ما كاد مصر تخرج نفوذ حكم يونان وقع حكم رومان سمر سقط يد عمر العاص دخل مصر حكم عرب تخلل فتر حكم مصر خلال مماليك والاخشيديون أخير عثماني الأتراك خضع فترة قصير انتداب بريطاني نال استقلال تأسس جمهور مصر حديث واذا استثنى فترة انتداب بريطاني حكومة فتح الاسلامي مصر حكومة إسلام منذ فتح الاسلامي مصر توافد عرب زرافة مصر جزيرة عرب لاحظ تاريخ مصر سياسة حضار مدون بدأ تولي الاسرة فرعون ٣٥٠٠ ميلاد تعدي قدم حضار عالم تدوين حكام محكوم وقت افارقة محلي نقول عن اصحاب سلال جين e سلال جين لافارقة جنوب صحراء ( أمازيغ نوبي حبش ) انتهى حكم مصر خرج يد حكام محلي دخول الإسكندر أكبر مقدوني مصر ظن سلال جين j٢ دخل مصر قدوم الآشوريين فرس مصر دخل سلال جين j١ دخول الآشوريين لان الساميين اختلط الاشوريين الامبراطورية الآشورية كانو مكون اجتماع إمبراطوري الاشورية بابلي سومر عراق والشام ازداد ضخ سلال جين j١ مصر فتح الاسلامي مصر استنتج سلال جين مصري أصلي e سلال جين j١ j٢ وافد أجانب مصر ذلك جبى نسى سلال جين الهندواوروبية r دخل مصر دخول البطالمة يونان مصر سلال جين أوروبي الاخرى دخل مصر دخول روم مصر بناء تقدم مستغرب ظهر المومياوات صلى عمر قارب ألف ميلاد سلال جين ( j١ j٢ r ) جوار سلال جين محل e\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(summary_ids)\n",
    "# print(input_ids)\n",
    "print(len(text))\n",
    "print(text)\n",
    "print(len(summary))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'التاريخ يقول ان غزو \" ا آشوريا \" لمصر حصل في القرن السابع قبل الميلاد واحتلت على اثره مصر لمدة تقارب المائة سنة تخللها مقاومة وحروب وقلاقل وثورات من المصريين لمقاومة الاحتلال الآشوري وفي النهاية استطاع المصريون طرد الآشوريين الغزاة لكن ما لبثوا ان غزاهم الفرس في منتصف القرن السادس قبل الميلاد وسقطت مصر في أيدي الفرس ورزحت تحت الاحتلال الفارسي قرابة 180 سنة بعد ان احتلها الآشوريون لمدة تقارب قرنا من الزمان ثم جاء اليونانيون بقيادة الإسكندر الأكبر المقدوني واحتل مصر وانهى الحقبة الفارسية في مصر واستمر حكم البطالمة لمصر قرابة ثلاثة قرون وما كادت مصر تخرج من نفوذ الحكم اليوناني حتى وقعت تحت الحكم الروماني واسمر حتى سقط على يد عمرو بن العاص فدخلت مصر تحت حكم العرب الى اليوم وان كان تخلله فترات حكم مصر خلالها المماليك والاخشيديون وأخيرا العثمانيون الأتراك وخضعت فترة قصيرة للانتداب البريطاني حتى نالت استقلالها وتأسست جمهورية مصر الحديثة واذا استثنينا فترة الانتداب البريطاني فان كل الحكومات من بعد الفتح الاسلامي لمصر حكومات إسلامية .. ومنذ الفتح الاسلامي لمصر توافد العرب زرافات الى مصر من جزيرة العرب ونلاحظ ان تاريخ مصر السياسي والحضاري المدون بدأ منذ تول الاسرة الفرعونية الاولى قبل 3500 سنة قبل الميلاد وهي بهذا تعد اقدم حضارة في العالم تم تدوينها .. وكان الحكام والمحكومين وقتها افارقة محليين يمكن ان نقول عنهم اصحاب السلالة الجينية e وهي السلالة الجينية لافارقة جنوب الصحراء ( أمازيغ ونوبيين وحبش ) .. وانتهى حكم مصر وخرج من أيدي الحكام المحليين بدخول الإسكندر الأكبر المقدوني لمصر .. وفي ظني ان السلالة الجينية j2 دخلت مصر مع قدوم الآشوريين والفرس الى مصر ودخلت السلالة الجينية j1 مع دخول الآشوريين ايضا لان بعض الساميين اختلطوا مع الاشوريين في الامبراطورية الآشورية وكانوا ضمن المكون الاجتماعي في الإمبراطوريات الاشورية والبابلية والسومرية في العراق والشام لكن ازداد ضخ السلالة الجينية j1 في مصر بعد الفتح الاسلامي لمصر ومن هنا نستنتج ان السلالة الجينية للمصريين الأصليين هي e والسلالتين الجينيتين j1,j2 للوافدين الأجانب الى مصر وكذلك يجب ان لا ننسى السلالة الجينية الهندواوروبية r التي دخلت مصر مع دخول البطالمة اليونان مصر والسلالات الجينية الأوروبية الاخرى دخلت مصر بدخول الرومان لمصر . وبناء على ما تقدم فانه من غير المستغرب ان تظهر المومياوات التي يصل عمرها الى ما يقارب الألف سنة قبل الميلاد على سلالات جينية (j1,j2,r) بجوار السلالة الجينية المحلية e'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "# Scores = []\n",
    "\n",
    "# for predicted, test in zip(Predicted_Summaries, Test_Summaries):\n",
    "#     score = Scorer.score(predicted, test)\n",
    "#     Scores.append(score)\n",
    "\n",
    "# Metrics = {\n",
    "#     \"rouge-1\": [score[\"rouge1\"].fmeasure for score in Scores],\n",
    "#     \"rouge-2\": [score[\"rouge2\"].fmeasure for score in Scores],\n",
    "#     \"rouge-l\": [score[\"rougeL\"].fmeasure for score in Scores]\n",
    "# }\n",
    "\n",
    "# print(Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': 0.0, 'rouge-2': 0.0, 'rouge-l': 0}\n"
     ]
    }
   ],
   "source": [
    "Scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "Scores = Scorer.score(Predicted_Summaries[0], Test_Summaries[0])\n",
    "\n",
    "Metrics = {\n",
    "    \"rouge-1\": Scores[\"rouge1\"].fmeasure,\n",
    "    \"rouge-2\": Scores[\"rouge2\"].fmeasure,\n",
    "    \"rouge-l\": Scores[\"rougeL\"].fmeasure,\n",
    "}\n",
    "\n",
    "print(Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'اعلنت \" لجنة جائزة بشارة الخوري للتوعية الديموقراطية \" انها انجزت المسابقة التي نظمتها حول \" دور الرئيس بشارة الخوري في تحقيق الميثاق والاستقلال \" بالتعاون مع وزارة التربية والتعليم العالي وبدعم من \" مؤسسة فريديريتش ايبرت \"، والتي شارك فيها طلاب الصف الثانوي الثاني بفرعيه العلمي والادبي والذين ينتمون الى مدارس رسمية وخاصة في المحافظات اللبنانية ، لافتة الى ان اعلان النتائج وتوزيع الجوائز سيتم خلال احتفال يقام عند الخامسة من بعد ظهر الخميس 30 الحالي في قصر الاونيسكو . واوضحت اللجنة في بيان \" ان المسابقة تناولت تاريخ لبنان الحديث من قيام دولة لبنان الكبير في الاول من ايلول 1920، الى الجلاء في 31 كانون الاول 1946، دور الرئيس بشارة الخوري في تحقيق الوحدة الوطنية واهمية الالتزام بالميثاق الوطني للمحافظة على الاستقلال \". واشارت \" الى ان الطلاب المشاركين اخضعوا في مرحلة اولى لامتحان خطي فاز في نهايته 69 طالبا ، ثم اشترك 17 منهم ممن نالوا العلامات الاعلى في المرحلة الثانية من المسابقة التي تضمنت امتحانا شفهيا امام لجنة فاحصة من الاساتذة المختصين اجابوا فيه على اسئلة تناولت فترة ولادة الاستقلال و الميثاق الوطني ودور الرئيسين بشارة الخوري ورياض الصلح في تلك المرحلة . وفي نتيجة الامتحان الشفهي فاز خمسة طلاب بالجائزة على ان تعلن اللجنة المنظمة عن اسمائهم خلال احتفال الاونيسكو ويتسلمون جوائزهم المادية والمعنوية . وذكرت اللجنة انها \" المرة الاولى التي تمنح فيها \" جائزة بشارة الخوري للتوعية الديموقراطية \" التي بدأ التحضير لها العام الماضي لمناسبة مرور 50 عاما على وفاة اول رئيس للجمهورية اللبنانية المستقلة ، على ان تكون هذه الجائزة سنوية وتخصص للاضاءة على ثوابت الاستقلال اللبناني واسس الميثاق الوطني ومبادئه \". وشكرت الذين تعاونوا لانجاح المسابقة ولاسيما المدير العام لوزارة التربية الدكتور فادي يرق والمسؤولين في الوزارة ومدراء المدارس الرسمية والخاصة التي شارك طلابها فيها والاساتذة الذين تولوا تصحيح المسابقات واجراء الامتحان الشفهي ، ومؤسسة فريدريتش ايبرت التي قدمت الجوائز للفائزين .'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predicted_Summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'قالت لجنة جائزة بشارة الخوري أنها اجتازت المسابقة التي نظمتها حول بشارة الخوري في أن يحقق الاستقلال، وقام طلبة الصف الثاني الثانوي بالمشاركة في مؤسسة فريديريتش ايبريت، وأن توزيع الجوائز يتم في احتفال يحدث الخامسة بعد الظهر، واللجنة قالت في بيان أن المسابقة كانت تحتوي على تاريخ لبنان الحديث، وأن بشارة الخوري حافظ على الالتزام بالميثاق لكي ينال الاستقلال، وأعلن عن أسماء الطلبة الفائزين في احتفال الأونيسكو.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Summaries[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
